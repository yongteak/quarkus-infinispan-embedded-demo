<infinispan>
    <jgroups transport="org.infinispan.remoting.transport.jgroups.JGroupsTransport">
        <stack name="mping">
            <!-- <MPING ispn:stack.combine="REMOVE" xmlns="urn:org:jgroups"/> -->
            <TCP bind_addr="192.168.12.113" bind_port="7800" port_range="30" recv_buf_size="20000000" send_buf_size="640000"
                sock_conn_timeout="300" bundler_type="transfer-queue"
                thread_pool.min_threads="0" thread_pool.max_threads="25" thread_pool.keep_alive_time="5000"
                thread_pool.thread_dumps_threshold="${jgroups.thread_dumps_threshold:10000}"
                xmlns="urn:org:jgroups"/>
            <!-- <TCPPING   initial_hosts="${infinispan.initial.hosts:localhost[7800]}"/> -->
            <TCPGOSSIP initial_hosts="${infinispan.initial.hosts:localhost[7800]}" xmlns="urn:org:jgroups"/>


            <!-- <TCP bind_addr="192.168.1.5" bind_port="7950"> -->
<!-- <TCPPING initial_hosts="192.168.1.5[7950],192.168.1.6[7900]"/> -->
            <!-- <stack name="tcpgossip" extends="tcp-test"> -->
            <!-- <MPING ispn:stack.combine="REMOVE" xmlns="urn:org:jgroups"/> -->
            <!-- <TCPGOSSIP initial_hosts="${jgroups.tunnel.gossip_router_hosts:localhost[12001]}" ispn:stack.combine="INSERT_AFTER" ispn:stack.position="RED" xmlns="urn:org:jgroups"/> -->
            <!-- <TCPGOSSIP initial_hosts="${infinispan.initial.hosts:localhost[7800]}" xmlns="urn:org:jgroups"/> -->
      <!-- </stack> -->
        </stack>
    

    </jgroups>
     <threads>
      <thread-factory name="infinispan-factory" group-name="infinispan" thread-name-pattern="%G %i" priority="5"/>
      <!-- listener-executor -->
      <blocking-bounded-queue-thread-pool name="infinispan-listener" thread-factory="infinispan-factory"
                                          core-threads="1" max-threads="1" queue-length="0" keepalive-time="0"/>

      <blocking-bounded-queue-thread-pool name="infinispan-blocking" thread-factory="infinispan-factory"
                                          core-threads="3" max-threads="8" queue-length="121" keepalive-time="9859" />

      <non-blocking-bounded-queue-thread-pool name="infinispan-non-blocking" thread-factory="infinispan-factory"
                                              core-threads="12" max-threads="15" queue-length="132" keepalive-time="9851" />
      <!-- expiration-executor -->
      <scheduled-thread-pool name="infinispan-expiration" thread-factory="infinispan-factory" />
   </threads>

    <cache-container default-cache="myDefaultCache">
    <!-- expiration-executor="infinispan-expiration"
                    listener-executor="infinispan-listener" non-blocking-executor="infinispan-non-blocking"
                    blocking-executor="infinispan-blocking"
                    statistics="true" shutdown-hook="DONT_REGISTER" zero-capacity-node="false"> -->
        <!-- 
            Infinispan에서 영속성을 사용하기 위해서는 먼저 전역 상태를 활성화해야 합니다. 
            전역 상태는 Infinispan 인스턴스의 중요한 메타데이터를 저장하는 데 사용되며, 
            영속성 설정과 같은 구성을 포함할 수 있습니다.

            전역 상태를 활성화한 후에는, 필요에 따라 전역 상태 데이터를 저장할 위치를 지정할 수 있습니다. 
            persistent-location과 temporary-location 속성을 사용하여 각각 영구 데이터와 임시
            데이터의 저장 위치를 지정할 수 있습니다:
        -->
        <!-- <global-state enabled="true">
            <persistent-location path="${infinispan.store.persistent.path:data}"/>
            <temporary-location path="${infinispan.store.temporary.path:data}"/>
            <overlay-configuration-storage />
        </global-state> -->

        <!-- <security>
         <authorization audit-logger="org.infinispan.security.audit.NullAuditLogger">
            <identity-role-mapper/>
            <roles>
               <role name="peasant" permissions="READ"/>
               <role name="vavasour" permissions="READ WRITE"/>
               <role name="vassal" permissions="READ WRITE LISTEN"/>
               <role name="king" permissions="ALL"/>
            </roles>
         </authorization>
      </security> -->
        <!-- <global-state>
            <persistent-location path="quarkus-persistentPath" relative-to="java.io.tmpdir" />
            <shared-persistent-location path="quarkus-sharedPath" relative-to="java.io.tmpdir" />
            <temporary-location path="quarkus-tmpPath" relative-to="java.io.tmpdir" />
            <overlay-configuration-storage />
      </global-state> -->
<!-- <file-store path="${infinispan.store.temporary.path:oraclizer/store/temporary/data}"/> -->
        <!-- <file-store path="/oraclizer/store/data" relative-to="user.home"/> -->
        <!--
            Infinispan에서의 분할 뇌 보호 전략
        Infinispan 9.2 이상에서는 새로운 분할 뇌 보호 기능이 도입되었습니다. 이 기능은 클러스터가 네트워크 분할로 인해 여러 파티션으로 나뉘었을 때, 각 파티션의 상태를 평가하고 하나의 파티션을 선택하여 데이터 일관성을 유지하는 방법을 제공합니다. 이를 위해 Infinispan은 다음과 같은 분할 뇌 보호 전략을 제공합니다:
        PREFERRED_ALWAYS: 항상 특정 파티션을 선호합니다.
        PREFERRED_NON_EMPTY: 비어 있지 않은 파티션을 선호합니다.
        REMOVE_ALL: 모든 파티션에서 데이터를 제거합니다.
        CUSTOM: 사용자 정의 로직을 통해 파티션을 선택합니다.
        이러한 전략은 캐시 컨테이너 또는 캐시 수준에서 설정할 수 있으며, 클러스터 환경과 애플리케이션의 요구 사항에 따라 적절한 전략을 선택해야 합니다.
        -->
        <!-- <partition-handling when-split="DENY_READ_WRITES" merge-policy="PREFERRED_NON_EMPTY"/> -->-->
        <transport cluster="${infinispan.cluster.name:local}"
                   stack="mping"
                   node-name="${infinispan.node.name:}">
            <properties>
                <!-- <property name="bind_port" value="7800"/> -->
                <!-- initial_hosts 설정 예시 -->
                <!-- <property name="initial_hosts" value="${infinispan.initial.hosts:}" /> -->
                <!-- 여기서 [7800]은 JGroups 통신에 사용되는 포트 번호입니다. 실제 환경에 맞게 조정하세요. -->
            </properties>
        </transport>
        
        <!-- export INFINISPAN_NODE_NAME=myNode1
        export QUARKUS_INFINISPAN_EMBEDDED_INFINISPAN_NODE_NAME=myNode000 -->
        <!-- 
        클러스터를 구성하는 모든 노드의 설정 파일에 initial_hosts 속성이 동일한 값으로 설정되어야 함을 의미합니다. 
        즉, 각 노드의 설정 파일에서 initial_hosts에 명시된 IP 주소와 포트 번호가 모두 같아야 한다는 것입니다. 
        이렇게 함으로써, 클러스터 내의 모든 노드가 시작 시 동일한 노드 목록을 바탕으로 서로를 찾고 연결할 수 있게 됩니다.
        이는 클러스터 형성 과정에서 모든 노드가 일관된 정보를 바탕으로 서로를 인식하고, 
        효율적으로 통신 네트워크를 구성할 수 있도록 하기 위함입니다. 만약 노드별로 initial_hosts 설정이 다르다면, 
        일부 노드가 클러스터에 제대로 참여하지 못하거나, 예상치 못한 네트워크 분할이 발생할 수 있습니다. 
        따라서 클러스터를 안정적으로 운영하려면 이 설정을 모든 노드에서 동일하게 유지하는 것이 중요합니다
        -->
        <!-- <properties> -->
            <!-- <property name="initial_hosts" value="10.1.1.1[7800],10.1.1.2[7800]" /> -->
            <!-- 여기서 [7800]은 JGroups 통신에 사용되는 포트 번호입니다. 실제 환경에 맞게 조정하세요. -->
        <!-- </properties> -->
        <!-- 분산 캐시 설정 템플릿 정의 -->
        <!--
            SYNC (동기 모드): 이 모드에서는 캐시 업데이트(삽입, 수정, 삭제 등)가 클러스터 내의 모든 노드에 
                동기적으로 반영됩니다. 즉, 작업이 완료되기 전에 모든 관련 노드가 업데이트를 받아야 합니다. 
                이는 데이터 일관성을 유지하는 데 유리하지만, 네트워크 지연으로 인해 성능이 저하될 수 있습니다.
            ASYNC (비동기 모드): 비동기 모드에서는 캐시 업데이트가 비동기적으로 수행됩니다. 
                작업을 요청한 노드는 다른 노드들이 업데이트를 완료할 때까지 기다리지 않고 
                즉시 다음 작업을 진행할 수 있습니다. 이는 성능을 향상시킬 수 있지만, 
                클러스터 내의 데이터 일관성을 보장하기 어려울 수 있습니다.
                => 최종 일관성(Eventual Consistency): 
                시간이 지남에 따라 모든 노드가 최종적으로 동일한 데이터 상태를 갖게 되는 것을 의미합니다. 
                비동기 모드에서는 업데이트가 지연될 수 있지만, 결국에는 모든 노드가 동기화됩니다.
        -->
        <global-state enabled="true" />
        <distributed-cache-configuration name="myDistributedCacheTemplate"
                                         mode="SYNC"
                                         statistics="true"
                                         owners="2"> <!-- 통계 활성화 -->
            <expiration lifespan="-1" max-idle="-1"/>                                        
            <encoding>
                <key media-type="text/plain"/>
                <value media-type="application/x-protostream"/>
            </encoding>
        </distributed-cache-configuration>
        <!-- 위에서 정의한 템플릿을 사용하여 "myDefaultCache"라는 이름의 분산 캐시 생성 -->
        <distributed-cache name="myDefaultCache" configuration="myDistributedCacheTemplate">
        <!--
            NON_XA: 간단한 트랜잭션을 지원합니다. XA(분산 트랜잭션)가 아닌 로컬 트랜잭션을 사용하여 리소스를 관리합니다. 
            이 모드는 여러 데이터 소스 간의 분산 트랜잭션을 필요로 하지 않는 경우에 적합합니다.
         -->
            <transaction mode="NON_XA"/>
            <persistence>
                <!-- <file-store path="${infinispan.store.path:/oraclizer/store/data}" relative-to="user.home"/> -->
                <!-- <file-store path="${infinispan.store.persistence.path:data}"/> -->
                <!-- <temporary-location path="/oraclizer/store/temporary/data" relative-to="user.home"/> -->
            </persistence>
            <!--
                timeout: 상태 전송 과정이 완료되기를 기다리는 최대 시간(밀리초 단위)입니다.
                chunk-size: 한 번에 전송되는 데이터의 최대 크기(바이트 단위)입니다.
            -->
            <state-transfer timeout="60000" chunk-size="1000"/>
            <!-- 
                네트워크 장애 시 업데이트 손실 가능성: 네트워크에 문제가 발생해 업데이트를 즉시 전송할 수 없는 경우, 
                해당 업데이트는 손실될 수 있습니다. 복제 큐가 비활성화되어 있기 때문에, 
                장애 상황에서 업데이트를 임시로 저장하고 나중에 전송할 방법이 없습니다.
             -->
            <!-- <async use-repl-queue="true" repl-queue-interval="5000" repl-queue-max-elements="1000"/> -->
            <!-- <security>
                <authorization roles="peasant vavasour vassal king"/>
            </security> -->
        </distributed-cache>
    </cache-container>
</infinispan>